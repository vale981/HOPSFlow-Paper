#+PROPERTY: header-args :session bath_memory :kernel python :pandoc no :async yes :tangle tangle/bath_memory.py

Here we scan bath memory and maybe temperature gradient later.

* Boilerplate
#+name: boilerplate
#+begin_src jupyter-python :results none
    import figsaver as fs
    import plot_utils as pu
    from hiro_models.one_qubit_model import StocProcTolerances
    from hiro_models.otto_cycle import OttoEngine
    import hiro_models.model_auxiliary as aux
    import numpy as np
    import qutip as qt
    import utilities as ut
    import stocproc
    import matplotlib.pyplot as plt
    import otto_utilities as ot

    import ray
    ray.shutdown()

    #ray.init(address='auto')
    ray.init()
    from hops.util.logging_setup import logging_setup
    import logging
    logging_setup(logging.INFO)
    plt.rcParams['figure.figsize'] = (12,4)
#+end_src

* Cycles
We take the same baseline as in [[id:c06111fd-d719-433d-a316-c163f6e1d384][cycle_shift.org]].


But we vary the cycle speed while keeping a fixed proportion
coupling-change/cycle time.
#+begin_src jupyter-python
  def make_shift_model(shift_c, shift_h, switch_t=3):
      switch_time = switch_t / 50

      (p_H, p_L) = ot.timings(switch_time, switch_time)
      return OttoEngine(
          δ=[.7, .7],
          ω_c=[1, 1],
          ψ_0=qt.basis([2], [1]),
          description=f"Classic Cycle",
          k_max=5,
          bcf_terms=[5] * 2,
          truncation_scheme="simplex",
          driving_process_tolerances=[StocProcTolerances(1e-3, 1e-3)] * 2,
          thermal_process_tolerances=[StocProcTolerances(1e-3, 1e-3)] * 2,
          T=[0.5, 4],
          therm_methods=["tanhsinh", "tanhsinh"],
          Δ=1,
          num_cycles=3,
          Θ=60,
          dt=0.001,
          timings_H=p_H,
          timings_L=p_L,
          streaming_mode=True,
          shift_to_resonance=(False, False),
          L_shift=(shift_c, shift_h),
      )

  def overlap(shift_model, N, step, switch_t=6):
      switch_time = switch_t / 50
      next_model = shift_model.copy()
      (p_H, p_L) = ot.timings(switch_time, switch_time)

      #next_model.timings_H=p_H
      next_model.timings_L=p_L

      (a, b, c, d) = next_model.timings_L[0]
      (e, f, g, h) = next_model.timings_L[1]
      next_step = step * N
      (s1, s2) = next_model.L_shift
      next_model.L_shift = (s1 + next_step, s2 - next_step)
      next_model.timings_L = (
          (a - 2 * next_step, b - 2 * next_step, c, d),
          (e, f, g + 2 * next_step, h + 2 * next_step),
      )
      return next_model

  def make_model(ω_c, T_c):
      best_shift_model = make_shift_model(.12, .12)
      new_step_size = 6
      mini_step = .12


      overlapped_model = overlap(best_shift_model, 1, mini_step, new_step_size)
      overlapped_model.T[0] = T_c
      overlapped_model.ω_c = [ω_c, ω_c]
      return overlapped_model
#+end_src

#+RESULTS:


#+begin_src jupyter-python
  ωs = [round(ω, 3) for ω in np.linspace(.5, 1.5, 5)]
  Ts = [round(T, 3) for T in np.linspace(.4, .6, 5)]
  ωs, Ts
#+end_src

#+RESULTS:
| 0.5 | 0.75 | 1.0 | 1.25 | 1.5 |
| 0.4 | 0.45 | 0.5 | 0.55 | 0.6 |

#+begin_src jupyter-python
  import itertools
  models = [make_model(ω, T) for ω, T, in itertools.product(ωs, Ts)]
#+end_src

#+RESULTS:


* Integrate
#+begin_src jupyter-python
  ot.integrate_online_multi(models, 30_000, increment=10_000, analyze_kwargs=dict(every=10_000))
#+end_src

* Analysis
#+begin_src jupyter-python
  models[1].T
#+end_src

#+RESULTS:
| 0.45 | 4 |

#+begin_src jupyter-python
  fig, ax = plt.subplots()
  for model in models[:22]:
      pu.plot_with_σ(models[0].t, model.interaction_power().sum_baths().integrate(model.t), ax=ax)
      print(model.power(steady_idx=2).value, model.T[0], model.ω_c[0])
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
  -0.006065467070030933 0.4 0.5
  -0.005591602311099003 0.45 0.5
  -0.005066588783212114 0.5 0.5
  -0.0046201846177245775 0.55 0.5
  -0.00408269304017506 0.6 0.5
  -0.006277295645870186 0.4 0.75
  -0.005888697577101804 0.45 0.75
  -0.005484333955351765 0.5 0.75
  -0.005117002574808731 0.55 0.75
  [WARNING root                      224434] Adding values with unequal snapshot count discards the snapshots.
  -0.004696002795276426 0.6 0.75
  -0.006000498375072689 0.4 1.0
  -0.005633957523771339 0.45 1.0
  -0.00525600486961774 0.5 1.0
  -0.004911341531730341 0.55 1.0
  -0.004569773623536163 0.6 1.0
  -0.005729676547086812 0.4 1.25
  -0.00534616431006602 0.45 1.25
  -0.0051525733640570715 0.5 1.25
  [WARNING root                      224434] Adding values with unequal snapshot count discards the snapshots.
  -0.004753746829381626 0.55 1.25
  -0.004446193855257419 0.6 1.25
  -0.00565830944810612 0.4 1.5
  -0.005324957406115274 0.45 1.5
#+end_example
[[file:./.ob-jupyter/4dedad5fb97c7875383b7ce3db9307f295f3cd18.svg]]
:END:

#+begin_src jupyter-python
  fig, ax = plt.subplots()
  for model in models[:22]:
    pu.plot_with_σ(models[0].t, model.system_energy(), ax=ax)
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/e528fb8f19cb154f99249ae08b8526951dd33e15.svg]]


#+begin_src jupyter-python
  pu.plot_with_σ(models[0].t, models[0].interaction_power().sum_baths().integrate(models[0].t))
#+end_src

#+RESULTS:
:RESULTS:
| <Figure | size | 1200x400 | with | 1 | Axes> | <AxesSubplot: | > | ((<matplotlib.lines.Line2D at 0x7fe105f9ab50>) <matplotlib.collections.PolyCollection at 0x7fe105f8ebb0>) |
[[file:./.ob-jupyter/4885b6623040daa45b75d948fb036da085c522c9.svg]]
:END:


#+begin_src jupyter-python
  ot.plot_power_eff_convergence(models[:10], 2)
#+end_src

#+RESULTS:
:RESULTS:
| <Figure | size | 340x320 | with | 2 | Axes> | (<AxesSubplot: xlabel= $N$ ylabel= $P$ > <AxesSubplot: xlabel= $N$ ylabel= $\eta$ >) |
[[file:./.ob-jupyter/7afe5e1a2790bc7742a36b7e0ea2e9f183cbfe10.svg]]
:END:



#+begin_src jupyter-python
  f = plt.figure()
  a_power = f.add_subplot(121, projection="3d")
  a_efficiency = f.add_subplot(122, projection="3d")

  for ax in [a_power, a_efficiency]:
      ax.set_box_aspect(aspect=None, zoom=0.7)
      ax.set_xlabel(r"$T_c$")
      ax.set_ylabel(r"$\omega_c$")
      ax.xaxis.labelpad = 10
      ax.view_init(elev=30.0, azim=-29, roll=0)

  ot.plot_3d_heatmap(
      models[:20],
      lambda model: np.clip(-model.power(steady_idx=2).value, 0, np.inf),
      lambda model: model.T[0],
      lambda model: model.ω_c[0],
      ax=a_power,
  )
  a_power.set_zlabel(r"$P$")


  ot.plot_3d_heatmap(
      models[:20],
      lambda model: np.clip(np.nan_to_num(model.efficiency(steady_idx=2).value * 100), 0, np.inf),
      lambda model: model.T[0],
      lambda model: model.ω_c[0],
      ax=a_efficiency,
  )
  a_efficiency.set_zlabel(r"$\eta$")
  fs.export_fig("bath_memory_power_efficiency", x_scaling=2, y_scaling=1)
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/07f1f1a19b9b33e5c9af58f399dcc478a044e932.svg]]

#+begin_src jupyter-python
  for model in models:
      ot.plot_bloch_components(model)
#+end_src

#+RESULTS:
:RESULTS:
: /home/hiro/Documents/Projects/UNI/master/eflow_paper/python/otto_motor/subprojects/bath_memory/plot_utils.py:38: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
:   fig, ax = setup_function()
[[file:./.ob-jupyter/290caad0bc7481e77b62e154e819a3052988a353.svg]]
[[file:./.ob-jupyter/e8b252cae59fda98a794a1ec1be821de8386bfa5.svg]]
[[file:./.ob-jupyter/7578e57c2ced88ece15aa2eb8b6b4fee31a86fa5.svg]]
[[file:./.ob-jupyter/ae083462a06f34430245f74bf8b2d505505b11eb.svg]]
[[file:./.ob-jupyter/40176c0b61de5fafbd76bae36933c18b792c162f.svg]]
[[file:./.ob-jupyter/a729c746c7584030b59c745f8a0da489ca2df9ac.svg]]
[[file:./.ob-jupyter/c5d3a792975c43c9ee13cbd35cd77d8d30d64545.svg]]
[[file:./.ob-jupyter/62cce9a31e649c315c5344a5b7ab145247956616.svg]]
[[file:./.ob-jupyter/384fce2c3614d7a3c678cdd6ce167cb7f79d9c4d.svg]]
[[file:./.ob-jupyter/38c2e2473864fc5c8f731ba6f48566030cf4a3a5.svg]]
[[file:./.ob-jupyter/d8a3afcfc35f9d9d9a40075c3fdeec8a8957cc93.svg]]
[[file:./.ob-jupyter/f14802ccf46f078c21dc8a1e26635af0f4ab39bf.svg]]
[[file:./.ob-jupyter/755d3c5d71fe3b8ec39131d3198952df31a17a7b.svg]]
[[file:./.ob-jupyter/7254949bf847513aba74771a2809597ae6b88033.svg]]
[[file:./.ob-jupyter/4590cfbf00cd6448b0b65ec24727b68ae2e21136.svg]]
[[file:./.ob-jupyter/cbfee4685e5aaecf1c4b798c4e4c233f644ec650.svg]]
[[file:./.ob-jupyter/b30c5747264f8a6194ed77ccfcdd50adeb76b51d.svg]]
[[file:./.ob-jupyter/d202e0b54a0770448a65999b95397ea5a6a44d18.svg]]
[[file:./.ob-jupyter/4b3603a3c8bbb86268330b623f48109473ec2fe9.svg]]
[[file:./.ob-jupyter/73a0bb3e1f65d2c16dce19d1cf1fd6bb0cbfd0f5.svg]]
[[file:./.ob-jupyter/3b040333e231c06777ba0e0f29b70b03a0eefd2f.svg]]
[[file:./.ob-jupyter/8079dc4f28185d6ec5de3f2d2e4b422e628a9131.svg]]
[[file:./.ob-jupyter/204937f1fb806f49218e6170aea443a25b2db635.svg]]
[[file:./.ob-jupyter/a3844b8ba0b86f0be89f72f5ccd2324ef7ea5a49.svg]]
[[file:./.ob-jupyter/8914fa0ef315a35e5864206fd7102bd509bd59e6.svg]]
:END:

* Things to Look At
- power and efficiency
- interaction power
